{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Airbnb Data Challenge"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Michael Kuhlen (10/02/2013)\n",
      "\n",
      "#### Note: I spent about 3 hours actually thinking through this project and doing the analysis, and then a little bit extra time to make the notebook look nice. ####"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Background ###\n",
      "\n",
      "Acme, a fictitious website, requests that users answer a few questions regarding their preferences prior to\n",
      "moving through the site. Answers are not required to move forward, but it is known that the user experience\n",
      "is better given that information."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Experiment ###\n",
      "\n",
      "A new landing page was tested.\n",
      "\n",
      "An A/B test was constructed so 50% of all users that reach the site are assigned to the old landing page.\n",
      "The old landing page is the control group. The remaining 50% are assigned to the new landing page. The\n",
      "new landing page is the treatment group.\n",
      "\n",
      "The historic completion rate for the landing page is 10%. An improvement to only 10.1% would provide a lift\n",
      "of 1%. If statistically significant, this would be considered a success.\n",
      "\n",
      "Acme uses a third-party, automated system to determine when to stop the experiment. It is supposed to\n",
      "stop the experiment when a significant difference between control and treatment has been reached."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Problem ###\n",
      "\n",
      "The project manager pushed for the new redesign and is very excited about it. She\u2019s concerned that the\n",
      "experiment stopped, but the results don\u2019t appear to be significant yet.\n",
      "\n",
      "She\u2019s asked you to check the results with Acme\u2019s own logs (since you don\u2019t have access to the third\u00adparty\n",
      "system\u2019s data)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Question 1 ###\n",
      "\n",
      "With the available data, what do you believe the results suggest? Do you have more confidence in Acme\u2019s\n",
      "data or the third party data? Why?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Answer 1 ###\n",
      "\n",
      "Before doing any data analysis, I have one major concern with the experimental setup.\n",
      "\n",
      "Checking the statistical significance of the result during data gathering raises a red flag for me. This procedure is highly problematic because it introduces a kind of \"bias\" into the result, which may cause the experimenter to conclude that the A/B test has produced a statistically significant result (e.g. the new landing page leads to a higher completion rate), when in reality the result is actually simply due to chance. This problem is sometimes referred to as \"interim monitoring problem\".\n",
      "\n",
      "The preferred way to do the experiment is to first determine how many samples will be needed to establish statistical significance at the desired confidence level. In this case the desired outcome is a 1% relative lift in completion rate, but the problem does not actually specify what the desired confidence level of this result should be. There are two user-tunable quantities of interest:\n",
      "\n",
      "1) Statistical power ($1-\\beta$): This is the fraction of A/B experiments in which the 1% relative change will actually be detectable, _if it really exists_.\n",
      "\n",
      "2) Significance level ($\\alpha$): This is the fraction A/B experiments which will report a 1% relative change, _even though there is no underlying difference_.\n",
      "\n",
      "Let's use $1-\\beta$ = 80% and $\\alpha$ = 5%, which are typical values. To obtain the necessary number of samples in each A/B bin, I used the handy online calculator at http://www.evanmiller.org/ab-testing/sample-size.html. For a baseline conversion of 10% and a minimum detectable effect of 1% relative change, this suggests that each of the A and B samples will need to consist of **1,414,681 samples** in order to give a result with statistical power of 80% and statistical significance level of 5%.\n",
      "\n",
      "A quick glance at experiments.csv reveals that there are only 90,815 control events and 100,333 treatment events. So the number of events are way too small (by roughly one order of magnitude) to support the conclusion at the stated confidence. Let's look at this data a little more closely."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "\n",
      "df = pd.read_csv('experiment.csv')\n",
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>user_id</th>\n",
        "      <th>ts</th>\n",
        "      <th>ab</th>\n",
        "      <th>landing_page</th>\n",
        "      <th>converted</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 4040615247</td>\n",
        "      <td> 1356998400</td>\n",
        "      <td> treatment</td>\n",
        "      <td> new_page</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 4365389205</td>\n",
        "      <td> 1356998400</td>\n",
        "      <td> treatment</td>\n",
        "      <td> new_page</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 4256174578</td>\n",
        "      <td> 1356998402</td>\n",
        "      <td> treatment</td>\n",
        "      <td> new_page</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 8122359922</td>\n",
        "      <td> 1356998402</td>\n",
        "      <td>   control</td>\n",
        "      <td> old_page</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 6077269891</td>\n",
        "      <td> 1356998402</td>\n",
        "      <td>   control</td>\n",
        "      <td> old_page</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "      user_id          ts         ab landing_page  converted\n",
        "0  4040615247  1356998400  treatment     new_page          0\n",
        "1  4365389205  1356998400  treatment     new_page          0\n",
        "2  4256174578  1356998402  treatment     new_page          0\n",
        "3  8122359922  1356998402    control     old_page          0\n",
        "4  6077269891  1356998402    control     old_page          0"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "control_df = df[df['ab'] == 'control']\n",
      "treatment_df = df[df['ab'] == 'treatment']\n",
      "\n",
      "print 'Number of control samples = %d' % len(control_df)\n",
      "print 'Number of treatment samples = %d' % len(treatment_df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of control samples = 90815\n",
        "Number of treatment samples = 100333\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conversion_rates = df['converted'].groupby(df['ab']).mean()*100\n",
      "conversion_rates.name = 'Conversion rates (in %)'\n",
      "print conversion_rates\n",
      "print\n",
      "print 'Difference in conversion rate = %.3f%%.' % \\\n",
      "    (conversion_rates[1] - conversion_rates[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ab\n",
        "control      9.964213\n",
        "treatment    9.994718\n",
        "Name: Conversion rates (in %), dtype: float64\n",
        "\n",
        "Difference in conversion rate = 0.031%.\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This brief analysis reveals that the difference in conversion rate is actually only about one third of the desired 0.1 percentage point (1% relative) lift.\n",
      "\n",
      "Not only is the sample size too small to support a statistically significant conclusion with reasonable confidence, **the data don't even contain the result we were hoping to see**, namely a 1% relative lift in conversion rate.\n",
      "\n",
      "Note that in order to establish statistical significance for this even smaller relative change we would need even larger sample sizes, **about 14.7 million samples each** for $1-\\beta$ = 80% and $\\alpha$ = 5%.\n",
      "\n",
      "With the given sample size, simple statistical fluctuations (i.e. chance) would produce a positive 0.03 percentage point difference quite commonly (around 40% of the time) even if there were no true difference in conversion rate, as the following calculation shows."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from scipy import stats\n",
      "\n",
      "## treatment sample size\n",
      "N = 100333\n",
      "\n",
      "## base (control) and observed (treatment) conversion rates\n",
      "p_base = 0.0996\n",
      "p_obs = 0.0999\n",
      "\n",
      "## the variance of the conversion rate (binomial)\n",
      "sigma2 = p_base*(1.0-p_base)\n",
      "\n",
      "## the standard error of the estimate of the conversion rate\n",
      "stderr = np.sqrt(sigma2 / N) \n",
      "\n",
      "## the z-score of the observed effect\n",
      "z_score = (p_obs - p_base) / stderr\n",
      "\n",
      "## the probability that such an effect would occur due to statistical\n",
      "## fluctuation, assuming a normally distributed random variable.\n",
      "Pchance =1.0 - stats.norm.cdf(z_score) \n",
      "\n",
      "print 'The probability of a conversion rate lift of %.2f%% ' \\\n",
      "   'arising from chance (given a sample size of %d) is %.1f%%.' % \\\n",
      "    ((p_obs-p_base)*100,N,Pchance*100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The probability of a conversion rate lift of 0.03% arising from chance (given a sample size of 100333) is 37.6%.\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In conclusion, it seems to me that the third party's system has some serious flaws. First I disagree with the methodology of stopping the experiment once a \"statistically significant\" result is reached, and secondly I believe there must be a serious bug in their software, since the reported increase in completion from 9.96% to 9.99% would occur simply due to statistical fluctuation roughly 40% of the time, and so is by no means statistically significant.\n",
      "\n",
      "For these reasons I have more confidence in Acme's own log data, and would strongly advise using it directly rather than relying on this shady third party software. I really hope Acme didn't spend much money on licensing it..."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Question 2 ###\n",
      "\n",
      "Knowing that the project manager is very smart, but that she is not a statistician, how would you explain it\n",
      "to her? What suggestions would you make for a future test?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Answer 2 ###\n",
      "\n",
      "Given that the project manager is very excited about the new layout, I would make an effort not to crush her enthusiasm. Clearly the data so far do not support the conclusion that the new layout has increased conversion in a statistically significant way, but that does not mean that a significant improvement won't eventually be seen.\n",
      "\n",
      "I would first explain to her that we are in fact seeing an increase in conversion, just that at the moment it's not as large as we had hoped for. At present it's only about a third of the 1% that we (perhaps somewhat arbitrarily) decided as the threshold for success. \n",
      "\n",
      "I would further caution that at present we cannot even be sure that this smaller effect is \"real\". With our limited sample size, we cannot confidently rule out that the observed increase is simply due to chance, i.e. to statistical fluctuation. Even if there were no intrinsic improvement in conversion arising from the new layout, if we repeated our experiment many times, we'd see an effect at least as big as what we're currently seeing in almost half (40%) of these experiments.  \n",
      "\n",
      "I would further emphasize that this **does not imply** that we should cancel the experiment, because in fact our third party software has \n",
      "made the dubious decision to prematurely stop the experiment. Too early to allow a significant detection of the desired effect, at any rate.\n",
      "\n",
      "I would suggest the following approach for the future:\n",
      "\n",
      "1) Abandoning our current engagement with this third party service, since they seem to be providing unreliable results. We can fairly easily do the test ourselves, and it will be more reliable and we'll be able to save money;\n",
      "\n",
      "2) We should first determine what statistical significance we would like our final result to have. 5% is a common choice. We would then determine how many samples we'd need to get to that level. Finally we would run the experiment until we got to the necessary number of samples.\n",
      "We should avoid peeking at the data beforehand, but if we have to look (human nature) we should really not let what we find make us deviate from our game plan. In other words, even if an early peek seems to reveal that the results are statistically significant prior to reaching the pre-determined sample size, we should nevertheless continue the experiment and evaluate it at the end.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Question 3 ###\n",
      "\n",
      "Additionally, a separate table lists user_id\u2019s and, if known, their country. Does the country data offer any\n",
      "additional insight?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Answer 3 ###\n",
      "\n",
      "I could imagine that some countries might respond much more strongly to the change in landing page. Perhaps one of the countries actually does exhibit a >1% relative change in conversion rate. This would still not overcome the problematic \"interim monitoring\" approach and the early stopping of the data gathering, but it may be interesting nevertheless. Let's have a look."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "\n",
      "df_country = pd.read_csv('country.csv')\n",
      "\n",
      "## some users have visited the site multiple times\n",
      "df_country.drop_duplicates(inplace=True)\n",
      "\n",
      "df_country.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>user_id</th>\n",
        "      <th>country</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 9160993935</td>\n",
        "      <td> UK</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 5879439034</td>\n",
        "      <td> UK</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 8915383273</td>\n",
        "      <td> UK</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 2917824565</td>\n",
        "      <td> US</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 3980216975</td>\n",
        "      <td> UK</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "      user_id country\n",
        "0  9160993935      UK\n",
        "1  5879439034      UK\n",
        "2  8915383273      UK\n",
        "3  2917824565      US\n",
        "4  3980216975      UK"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What countries are represented and how many samples are there in each country?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print df_country.groupby(df_country['country']).size()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "country\n",
        "CA          30024\n",
        "UK          50194\n",
        "US         100260\n",
        "dtype: int64\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Left join the country dataframe to original dataframe."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Note: this alters the original dataframe (df),\n",
      "## so this cell should not be executed more than once.\n",
      "\n",
      "df = pd.merge(df,df_country, on='user_id', how='left')\n",
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>user_id</th>\n",
        "      <th>ts</th>\n",
        "      <th>ab</th>\n",
        "      <th>landing_page</th>\n",
        "      <th>converted</th>\n",
        "      <th>country</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 4040615247</td>\n",
        "      <td> 1356998400</td>\n",
        "      <td> treatment</td>\n",
        "      <td> new_page</td>\n",
        "      <td> 0</td>\n",
        "      <td> US</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 4365389205</td>\n",
        "      <td> 1356998400</td>\n",
        "      <td> treatment</td>\n",
        "      <td> new_page</td>\n",
        "      <td> 0</td>\n",
        "      <td> US</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 4256174578</td>\n",
        "      <td> 1356998402</td>\n",
        "      <td> treatment</td>\n",
        "      <td> new_page</td>\n",
        "      <td> 0</td>\n",
        "      <td> US</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 8122359922</td>\n",
        "      <td> 1356998402</td>\n",
        "      <td>   control</td>\n",
        "      <td> old_page</td>\n",
        "      <td> 0</td>\n",
        "      <td> US</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 6077269891</td>\n",
        "      <td> 1356998402</td>\n",
        "      <td>   control</td>\n",
        "      <td> old_page</td>\n",
        "      <td> 0</td>\n",
        "      <td> UK</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "      user_id          ts         ab landing_page  converted country\n",
        "0  4040615247  1356998400  treatment     new_page          0      US\n",
        "1  4365389205  1356998400  treatment     new_page          0      US\n",
        "2  4256174578  1356998402  treatment     new_page          0      US\n",
        "3  8122359922  1356998402    control     old_page          0      US\n",
        "4  6077269891  1356998402    control     old_page          0      UK"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Check to make sure that the join didn't screw up anything with\n",
      "## the total conversion rates\n",
      "\n",
      "df['converted'].groupby(df['ab']).mean()\n",
      "\n",
      "## Output matches what we had above, so we're ok.\n",
      "##\n",
      "## Note: this is how I discovered that some users visited the site\n",
      "## multiple times, because prior to removing the duplicates the left\n",
      "## join ended up shuffling the 'converted' values around... "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "ab\n",
        "control      0.099642\n",
        "treatment    0.099947\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Give conversion rates grouped by country and A/B bin."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conversion_rates = \\\n",
      "    df['converted'].groupby([df['country'],df['ab']]).mean()\n",
      "conversion_rates.name = 'Conversion Rate'\n",
      "print conversion_rates\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "country  ab       \n",
        "CA       control      0.101217\n",
        "         treatment    0.098325\n",
        "UK       control      0.102032\n",
        "         treatment    0.099606\n",
        "US       control      0.098437\n",
        "         treatment    0.101653\n",
        "Name: Conversion Rate, dtype: float64\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The difference between control and treatment conversion rate, grouped by country."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conv_rate_diff = \\\n",
      "   (conversion_rates.ix[:,'treatment'] - conversion_rates.ix[:,'control'])\n",
      "conv_rate_diff.name = 'Conversion Rate Difference'\n",
      "print conv_rate_diff\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "country\n",
        "CA        -0.002892\n",
        "UK        -0.002426\n",
        "US         0.003217\n",
        "Name: Conversion Rate Difference, dtype: float64\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Interestingly, the differences grouped by country are indeed much larger than for the aggregated sample! \n",
      "\n",
      "For visitors from the US, the conversion has increased by 0.3%, which is three times larger than our desired effect of 0.1%. This looks promising. Is this a statistically significant effect (for $1-\\beta$ = 0.8 and $\\alpha$ = 0.05)?\n",
      "\n",
      "Going back to the online sample size calculator, I find that we'd need a sample size of roughly 135,000. This is still a bit larger than our actual sample of 100,260, but not by much. If we relaxed our criteria for statistical significance a little bit, we'd be in the clear. For example, if had we chosen $1 - \\beta$ = 0.7, or $\\alpha$ = 0.1, or $(1-\\beta, \\alpha)$ = (0.75, 0.07). Of course changing your significance criteria after the fact is also somewhat dubious.\n",
      "\n",
      "The other interesting trend is that the conversion rates have actually _decreased_ for visitors from Canada and the UK. Again, neither of these effects are statistically significant (for the default values of $1-\\beta$ and $\\alpha$), but they almost are. These are interesting trends to revisit once the larger sample sizes have been obtained.\n",
      "\n",
      "Perhaps the new landing page uses some US-specific design elements (like huge stars and stripes), which appeal to US users but turn off users from Canada and the UK?"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}